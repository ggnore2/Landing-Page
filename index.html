<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="./assets/fonts/themify-icons/themify-icons.css">
    <link rel="stylesheet" href="./assets/css/base.css">
    <link rel="stylesheet" href="./assets/css/main.css">
</head>
<body>
    <div class="container-fluid">
        <div class="container-md">
            <div class="header">
                <div class="row">
                    <div class="col">
                        <p class="header-heading text-center">Tên Đề Tài</p>
                        <div class="header-members d-flex justify-content-center">
                            <a href="#" class="header-members-link">Member 1: Công</a>
                            <a href="#" class="header-members-link">Member 2: An</a>
                            <a href="#" class="header-members-link">Member 3: Vũ Tùng</a>
                            <a href="#" class="header-members-link">Member 4: Sang</a>
                            <a href="https://TanDat6189.github.io/" class="header-members-link">Member 5: Tấn Đạt</a>
                        </div>
                        <div class="header-documents d-flex justify-content-center">
                            <a href="" class="header-documents-link">[DEMO]</a>
                            <a href="" class="header-documents-link">[GitHub]</a>
                            <a href="" class="header-documents-link">[Talk]</a>
                            <a href="" class="header-documents-link">[Slides]</a>
                            <a href="" class="header-documents-link">[Paper]</a>
                            <a href="" class="header-documents-link">[Poster]</a>
                        </div>
                        <div class="header-check-out text-center">
                            Also check out our new work on
                            <a href="#" class="header-check-out-link">Interactive Deep Colorization</a>
                            !
                        </div>
                        <img src="https://richzhang.github.io/colorization/resources/images/teaser3.jpg" alt="" class="header-img">
                        <p class="header-img-desc text-center">Example input grayscale photos and output colorizations from our algorithm. These examples are cases where our model works especially well. For randomly selected examples, see the Performance comparisons section below.</p>
                        
                        <hr>
                    </div>
                </div>
            </div>

            <div class="content">
                <div class="row">
                    <div class="col">
                        <div class="content__abstract">
                            <h1 class="content__abstract-heading text-center">Abstract</h1>
                            <p class="content__abstract-desc">
                                Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test," asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.
                            </p>

                            <hr>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>